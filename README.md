# Pyspark
This repository will contain all the information related to Pyspark and also some codings related to data.

Pyspark is a tool which uses the Python API to interact with its server to manage large data operations.
Pyspark basically follows the basic 3 functions in its back end server during any operations.
  1. Driver Program - which will assign "work node" (small computers/labours/workers) which will perform individual sub-task
  2. Cluster Manger - which will monitor the "work node" functionality and process. It assigns memeory and compute to the work node
  3. Work node - which are the sub-computers or workers which will perform all the related sub-task and output the desired result.
